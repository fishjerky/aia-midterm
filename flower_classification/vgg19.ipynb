{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "#import keras_resnet.models\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Dropout, BatchNormalization, Conv2D, MaxPooling2D, AveragePooling2D, concatenate, \\\n",
    "    Activation, ZeroPadding2D\n",
    "from keras.layers import add, Flatten\n",
    "from keras.utils import plot_model\n",
    "from keras.metrics import top_k_categorical_accuracy\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import ReduceLROnPlateau, CSVLogger,ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\n",
    "from keras import backend as K\n",
    "from keras import optimizers\n",
    "from keras import applications\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.applications.vgg19 import preprocess_input\n",
    "#from keras.applications.vgg16 import VGG16\n",
    "#from keras.applications.vgg16 import preprocess_input\n",
    "#from keras.applications import vgg16\n",
    "from sklearn.utils import shuffle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import cv2\n",
    "import os\n",
    "data_src = '//data/examples/flower_classification/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''設定參數'''\n",
    "classn = 5\n",
    "batch_size = classn * 2\n",
    "epochs = 80\n",
    "lr = 0.0001\n",
    "train_ratio= 0.8\n",
    "sz=224\n",
    "r_state = 40\n",
    "channel = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelmap=pd.read_csv(data_src+'mapping.csv',names=['dirs','class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:1: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "sortlabel=labelmap.sort('class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['daisy', 'dandelion', 'rose', 'sunflower', 'tulip']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targetlist=sortlabel.dirs.as_matrix().tolist()\n",
    "targetlist[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "targetlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-891e03300140>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mimg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msz\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;31m#img=cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# cv2 預設讀進來是 BGR, 我們要轉回 RGB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0;31m# zero-mean\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m# pre-trained model 使用 ImageNet 做訓練\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "x=[]\n",
    "y=[]\n",
    "for i,c in enumerate(targetlist):\n",
    "    ff=glob.glob((data_src+'train/'+c+'/*jpg'))\n",
    "    for f in ff:\n",
    "        img=cv2.imread(f) #img=cv2.imread(f, 0 )\n",
    "        img=cv2.resize(img,(sz,sz))\n",
    "        img=cv2.cvtColor(img, cv2.COLOR_RGB2BGR) #COLOR_GRAY2BGR\n",
    "        img = img[:,:,::-1] # cv2 預設讀進來是 BGR, 我們要轉回 RGB\n",
    "        # zero-mean\n",
    "        # pre-trained model 使用 ImageNet 做訓練\n",
    "        # ImageNet 的所有影像 RGB 平均值 [123.68, 116.78, 103.94]\n",
    "        #img = img.astype('float32') - np.array([123.68, 116.78, 103.94])\n",
    "        img = img.astype('float32')\n",
    "        x.append(img)\n",
    "        nn=np.zeros(15,dtype=float)\n",
    "        nn[i]=1\n",
    "        y.append(nn)\n",
    "xx=np.array(x)\n",
    "yy=np.array(y)\n",
    "\n",
    "xx = preprocess_input(xx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------資料training set, testing set 分割---------------------------------------\n",
    "\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(xx, \n",
    "                                                      yy, \n",
    "                                                      test_size = 1.0 - train_ratio,\n",
    "                                                      stratify = y,\n",
    "                                                      random_state = r_state)\n",
    "#------------------------------------檢查資料---------------------------------------------------------\n",
    "print(\"training set data dimension\")\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(\"-----------\")\n",
    "print(\"training set: %i\" % len(x_train))\n",
    "print(\"validation set: %i\" % len(x_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_valid = x_valid.astype('float32')\n",
    "\n",
    "\n",
    "# subtract mean and normalize\n",
    "mean_image = np.mean(x_train, axis=0)\n",
    "x_train -= mean_image\n",
    "x_valid -= mean_image\n",
    "x_train /= 255.\n",
    "x_valid /= 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.01), cooldown=0, patience=5, min_lr=0.5e-6)\n",
    "early_stopper = EarlyStopping(min_delta=0.01, patience=10)\n",
    "mcp_save = ModelCheckpoint('best.hdf5', save_best_only=True, monitor='val_loss', mode='min')\n",
    "csv_logger = CSVLogger('resnet18.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks=[lr_reducer, early_stopper, csv_logger,mcp_save]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=True,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        shear_range = 0.1,\n",
    "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "# datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = applications.VGG19(weights = \"imagenet\", include_top=False, input_shape = (sz, sz, channel))\n",
    "\n",
    "# Freeze the layers which you don't want to train. Here I am freezing the first 5 layers.\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "#Adding custom Layers \n",
    "x = model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(1024, activation=\"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(1024, activation=\"relu\")(x)\n",
    "predictions = Dense(15, activation=\"softmax\")(x)\n",
    "\n",
    "# creating the final model \n",
    "model_final = Model(input = model.input, output = predictions)\n",
    "\n",
    "# compile the model \n",
    "model_final.compile(loss = \"categorical_crossentropy\", optimizer=optimizers.RMSprop(lr=lr), metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "history = model_final.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                                    steps_per_epoch=x_train.shape[0] / batch_size,\n",
    "                                    validation_data=(x_valid, y_valid),  \n",
    "                                    epochs=epochs, \n",
    "                                    callbacks=[lr_reducer, early_stopper, csv_logger,mcp_save])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdata=pd.read_csv(data_src+'submission.csv')\n",
    "testdata.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "testdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdataindexlist=testdata.id.as_matrix().tolist()\n",
    "testdataindexlist[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_t=[]\n",
    "for f in testdataindexlist:\n",
    "    img=cv2.imread(data_src+'test/'+f+'.jpg') #,1\n",
    "    img=cv2.resize(img,(sz,sz))\n",
    "    img=cv2.cvtColor(img, cv2.COLOR_RGB2BGR) #COLOR_GRAY2BGR\n",
    "    img = img[:,:,::-1]\n",
    "    #img = img.astype('float32') - np.array([123.68, 116.78, 103.94])\n",
    "    img = img.astype('float32')\n",
    "    x_t.append(img)\n",
    "\n",
    "        \n",
    "x_test=np.array(x_t)\n",
    "x_test = preprocess_input(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%script false\n",
    "model_final.load_weights(filepath = 'best.hdf5')\n",
    "\n",
    "score = model_final.evaluate(x_train, y_train, verbose=2)\n",
    "print(\"Best model\")\n",
    "print('\\t-CV loss:', score[0])\n",
    "print('\\t-CV accuracy:', score[1])\n",
    "\n",
    "pt = model_final.predict(x_train)\n",
    "mse = (np.mean((pt-y_train)**2))\n",
    "print('\\t-CV MSE: ', mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts = model_final.predict(x_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "codeMap = {}\n",
    "maxPossible = np.argmax(predicts,axis=1)\n",
    "for i in range(0, len(predicts)):\n",
    "    filename = testdata.id[i]\n",
    "    code = maxPossible[i]\n",
    "    codeMap[code] = code\n",
    "#     print(i)\n",
    "    result.append([filename,code])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer=pd.DataFrame(result,columns=['id','class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer.to_csv('vgg19-submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
