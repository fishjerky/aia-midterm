{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import resnet\n",
    "#import keras_resnet.models\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Dropout, BatchNormalization, Conv2D, MaxPooling2D, AveragePooling2D, concatenate, \\\n",
    "    Activation, ZeroPadding2D\n",
    "from keras.layers import add, Flatten\n",
    "from keras.utils import plot_model\n",
    "from keras.metrics import top_k_categorical_accuracy\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import ReduceLROnPlateau, CSVLogger,ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\n",
    "from keras import backend as K\n",
    "from keras import optimizers\n",
    "from keras import applications\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.applications.vgg19 import preprocess_input\n",
    "#from keras.applications.vgg16 import VGG16\n",
    "#from keras.applications.vgg16 import preprocess_input\n",
    "#from keras.applications import vgg16\n",
    "from sklearn.utils import shuffle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import cv2\n",
    "import os\n",
    "data_src = '//data/examples/may_the_4_be_with_u/where_am_i/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''設定參數'''\n",
    "classn = 15\n",
    "batch_size = classn * 2\n",
    "epochs = 80\n",
    "lr = 0.0001\n",
    "train_ratio= 0.8\n",
    "sz=224\n",
    "r_state = 40\n",
    "channel = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelmap=pd.read_csv(data_src+'mid_term_mapping.txt',names=['place','index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:1: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "sortlabel=labelmap.sort('index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['kitchen', 'street', 'industrial', 'insidecity', 'forest']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targetlist=sortlabel.place.as_matrix().tolist()\n",
    "targetlist[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "targetlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=[]\n",
    "y=[]\n",
    "for i,c in enumerate(targetlist):\n",
    "    ff=glob.glob((data_src+'train/'+c+'/*jpg'))\n",
    "    for f in ff:\n",
    "        img=cv2.imread(f, 0 )\n",
    "        img=cv2.resize(img,(sz,sz))\n",
    "        img=cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "        img = img[:,:,::-1] # cv2 預設讀進來是 BGR, 我們要轉回 RGB\n",
    "        # zero-mean\n",
    "        # pre-trained model 使用 ImageNet 做訓練\n",
    "        # ImageNet 的所有影像 RGB 平均值 [123.68, 116.78, 103.94]\n",
    "        #img = img.astype('float32') - np.array([123.68, 116.78, 103.94])\n",
    "        img = img.astype('float32')\n",
    "        x.append(img)\n",
    "        nn=np.zeros(15,dtype=float)\n",
    "        nn[i]=1\n",
    "        y.append(nn)\n",
    "xx=np.array(x)\n",
    "yy=np.array(y)\n",
    "\n",
    "xx = preprocess_input(xx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2985, 224, 224, 3)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2985, 15)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set data dimension\n",
      "(2388, 224, 224, 3)\n",
      "(2388, 15)\n",
      "-----------\n",
      "training set: 2388\n",
      "validation set: 597\n"
     ]
    }
   ],
   "source": [
    "#----------------------------資料training set, testing set 分割---------------------------------------\n",
    "\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(xx, \n",
    "                                                      yy, \n",
    "                                                      test_size = 1.0 - train_ratio,\n",
    "                                                      stratify = y,\n",
    "                                                      random_state = r_state)\n",
    "#------------------------------------檢查資料---------------------------------------------------------\n",
    "print(\"training set data dimension\")\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(\"-----------\")\n",
    "print(\"training set: %i\" % len(x_train))\n",
    "print(\"validation set: %i\" % len(x_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_valid = x_valid.astype('float32')\n",
    "\n",
    "\n",
    "# subtract mean and normalize\n",
    "mean_image = np.mean(x_train, axis=0)\n",
    "x_train -= mean_image\n",
    "x_valid -= mean_image\n",
    "x_train /= 255.\n",
    "x_valid /= 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.01), cooldown=0, patience=5, min_lr=0.5e-6)\n",
    "early_stopper = EarlyStopping(min_delta=0.01, patience=10)\n",
    "mcp_save = ModelCheckpoint('best.hdf5', save_best_only=True, monitor='val_loss', mode='min')\n",
    "csv_logger = CSVLogger('resnet18.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks=[lr_reducer, early_stopper, csv_logger,mcp_save]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=True,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        shear_range = 0.1,\n",
    "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "# datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:16: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "80/79 [==============================] - 22s 281ms/step - loss: 4.7869 - acc: 0.4604 - val_loss: 1.5706 - val_acc: 0.7437\n",
      "Epoch 2/80\n",
      "80/79 [==============================] - 20s 246ms/step - loss: 2.3362 - acc: 0.6667 - val_loss: 0.9045 - val_acc: 0.8258\n",
      "Epoch 3/80\n",
      "80/79 [==============================] - 15s 189ms/step - loss: 1.6204 - acc: 0.7390 - val_loss: 1.2993 - val_acc: 0.8007\n",
      "Epoch 4/80\n",
      "80/79 [==============================] - 16s 198ms/step - loss: 1.4673 - acc: 0.7687 - val_loss: 0.9350 - val_acc: 0.8459\n",
      "Epoch 5/80\n",
      "80/79 [==============================] - 21s 263ms/step - loss: 1.4299 - acc: 0.7786 - val_loss: 0.7621 - val_acc: 0.8794\n",
      "Epoch 6/80\n",
      "80/79 [==============================] - 16s 197ms/step - loss: 1.2266 - acc: 0.8043 - val_loss: 0.9267 - val_acc: 0.8593\n",
      "Epoch 7/80\n",
      "80/79 [==============================] - 16s 200ms/step - loss: 1.0949 - acc: 0.8244 - val_loss: 0.8763 - val_acc: 0.8844\n",
      "Epoch 8/80\n",
      "80/79 [==============================] - 16s 196ms/step - loss: 1.0378 - acc: 0.8388 - val_loss: 0.8153 - val_acc: 0.8760\n",
      "Epoch 9/80\n",
      "80/79 [==============================] - 21s 260ms/step - loss: 1.0657 - acc: 0.8283 - val_loss: 0.6175 - val_acc: 0.9012\n",
      "Epoch 10/80\n",
      "80/79 [==============================] - 16s 197ms/step - loss: 0.9788 - acc: 0.8426 - val_loss: 0.6999 - val_acc: 0.8978\n",
      "Epoch 11/80\n",
      "80/79 [==============================] - 16s 197ms/step - loss: 0.8459 - acc: 0.8593 - val_loss: 0.7364 - val_acc: 0.8995\n",
      "Epoch 12/80\n",
      "80/79 [==============================] - 16s 202ms/step - loss: 0.7980 - acc: 0.8783 - val_loss: 0.7750 - val_acc: 0.8961\n",
      "Epoch 13/80\n",
      "80/79 [==============================] - 16s 200ms/step - loss: 0.7762 - acc: 0.8751 - val_loss: 0.6455 - val_acc: 0.9129\n",
      "Epoch 14/80\n",
      "80/79 [==============================] - 23s 283ms/step - loss: 0.7728 - acc: 0.8742 - val_loss: 0.6030 - val_acc: 0.9079\n",
      "Epoch 15/80\n",
      "80/79 [==============================] - 17s 210ms/step - loss: 0.7914 - acc: 0.8717 - val_loss: 0.6932 - val_acc: 0.8995\n",
      "Epoch 16/80\n",
      "80/79 [==============================] - 16s 197ms/step - loss: 0.7460 - acc: 0.8761 - val_loss: 0.6685 - val_acc: 0.9062\n",
      "Epoch 17/80\n",
      "80/79 [==============================] - 17s 214ms/step - loss: 0.7340 - acc: 0.8853 - val_loss: 0.6422 - val_acc: 0.9028\n",
      "Epoch 18/80\n",
      "80/79 [==============================] - 16s 205ms/step - loss: 0.7711 - acc: 0.8854 - val_loss: 0.7249 - val_acc: 0.8978\n",
      "Epoch 19/80\n",
      "80/79 [==============================] - 16s 194ms/step - loss: 0.7660 - acc: 0.8836 - val_loss: 0.6878 - val_acc: 0.9062\n",
      "Epoch 20/80\n",
      "80/79 [==============================] - 16s 202ms/step - loss: 0.6686 - acc: 0.9032 - val_loss: 0.6281 - val_acc: 0.9196\n",
      "Epoch 21/80\n",
      "80/79 [==============================] - 16s 196ms/step - loss: 0.5797 - acc: 0.9117 - val_loss: 0.6406 - val_acc: 0.9129\n",
      "Epoch 22/80\n",
      "80/79 [==============================] - 18s 228ms/step - loss: 0.4750 - acc: 0.9199 - val_loss: 0.6264 - val_acc: 0.9129\n",
      "Epoch 23/80\n",
      "80/79 [==============================] - 18s 221ms/step - loss: 0.4528 - acc: 0.9251 - val_loss: 0.6472 - val_acc: 0.9095\n",
      "Epoch 24/80\n",
      "80/79 [==============================] - 16s 198ms/step - loss: 0.5125 - acc: 0.9171 - val_loss: 0.6533 - val_acc: 0.9095\n"
     ]
    }
   ],
   "source": [
    "model = applications.VGG19(weights = \"imagenet\", include_top=False, input_shape = (sz, sz, channel))\n",
    "\n",
    "# Freeze the layers which you don't want to train. Here I am freezing the first 5 layers.\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "#Adding custom Layers \n",
    "x = model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(1024, activation=\"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(1024, activation=\"relu\")(x)\n",
    "predictions = Dense(15, activation=\"softmax\")(x)\n",
    "\n",
    "# creating the final model \n",
    "model_final = Model(input = model.input, output = predictions)\n",
    "\n",
    "# compile the model \n",
    "model_final.compile(loss = \"categorical_crossentropy\", optimizer=optimizers.RMSprop(lr=lr), metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "history = model_final.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                                    steps_per_epoch=x_train.shape[0] / batch_size,\n",
    "                                    validation_data=(x_valid, y_valid),  \n",
    "                                    epochs=epochs, \n",
    "                                    callbacks=[lr_reducer, early_stopper, csv_logger,mcp_save])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdata=pd.read_csv(data_src+'img-submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "testdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdataindexlist=testdata.id.as_matrix().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_t=[]\n",
    "for f in testdataindexlist:\n",
    "    img=cv2.imread(data_src+'testset/'+f+'.jpg',0)\n",
    "    img=cv2.resize(img,(sz,sz))\n",
    "    img=cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "    img = img[:,:,::-1]\n",
    "    #img = img.astype('float32') - np.array([123.68, 116.78, 103.94])\n",
    "    img = img.astype('float32')\n",
    "    x_t.append(img)\n",
    "\n",
    "        \n",
    "x_test=np.array(x_t)\n",
    "x_test = preprocess_input(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model\n",
      "\t-CV loss: 0.177443539749\n",
      "\t-CV accuracy: 0.971943048576\n",
      "\t-CV MSE:  0.00341232536097\n"
     ]
    }
   ],
   "source": [
    "#%%script false\n",
    "model_final.load_weights(filepath = 'best.hdf5')\n",
    "\n",
    "score = model_final.evaluate(x_train, y_train, verbose=2)\n",
    "print(\"Best model\")\n",
    "print('\\t-CV loss:', score[0])\n",
    "print('\\t-CV accuracy:', score[1])\n",
    "\n",
    "pt = model_final.predict(x_train)\n",
    "mse = (np.mean((pt-y_train)**2))\n",
    "print('\\t-CV MSE: ', mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500/1500 [==============================] - 7s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "predicts = model_final.predict(x_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "codeMap = {}\n",
    "maxPossible = np.argmax(predicts,axis=1)\n",
    "for i in range(0, 1500):\n",
    "    filename = testdata.id[i]\n",
    "    code = maxPossible[i]\n",
    "    codeMap[code] = code\n",
    "#     print(i)\n",
    "    result.append([filename,code])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['c117693e1cf24a5232090d1548cb11d4e5ea0df65680c4a56a8e8aa2beede330', 12],\n",
       " ['96baacc2e97886a998807ce197574821a6dc83c227c7469961c01ab315908371', 14],\n",
       " ['f9bd26db23eb9b544ca78be79b11b4d1259e802885861d8b66a8e709995229db', 0],\n",
       " ['b42bcd8e6645fcc2ac40ee44b7dc8d74a77081d0aea7a1a88eaba3d8393001c3', 5],\n",
       " ['5bc53cef9168882f0ff67a81b3e7269f62b7fd5343d06dafe63570d5032c21f3', 2]]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer=pd.DataFrame(result,columns=['id','class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer.to_csv('img-submission20.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
