{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "#import keras_resnet.models\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Dropout, BatchNormalization, Conv2D, MaxPooling2D, AveragePooling2D, concatenate, \\\n",
    "    Activation, ZeroPadding2D\n",
    "from keras.layers import add, Flatten, GlobalAveragePooling2D\n",
    "from keras.utils import plot_model\n",
    "from keras.metrics import top_k_categorical_accuracy\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import ReduceLROnPlateau, CSVLogger,ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\n",
    "from keras import backend as K\n",
    "from keras import optimizers\n",
    "from keras import applications\n",
    "from keras.applications.xception import Xception\n",
    "from keras.applications.xception import preprocess_input\n",
    "#from keras.applications.vgg16 import VGG16\n",
    "#from keras.applications.vgg16 import preprocess_input\n",
    "#from keras.applications import vgg16\n",
    "from sklearn.utils import shuffle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import cv2\n",
    "import os\n",
    "data_src = '//data/examples/flower_classification/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''設定參數'''\n",
    "classn = 15\n",
    "batch_size = classn * 2\n",
    "epochs = 80\n",
    "lr = 0.0001\n",
    "train_ratio= 0.8\n",
    "sz=299\n",
    "r_state = 40\n",
    "channel = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelmap=pd.read_csv(data_src+'mapping.csv',names=['dirs','class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:1: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "sortlabel=labelmap.sort('class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['daisy', 'dandelion', 'rose', 'sunflower', 'tulip']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targetlist=sortlabel.dirs.as_matrix().tolist()\n",
    "targetlist[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "targetlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=[]\n",
    "y=[]\n",
    "for i,c in enumerate(targetlist):\n",
    "    ff=glob.glob((data_src+'train/'+c+'/*jpg'))\n",
    "    for f in ff:\n",
    "        img=cv2.imread(f )\n",
    "        img=cv2.resize(img,(sz,sz))\n",
    "        img=cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = img[:,:,::-1] # cv2 預設讀進來是 BGR, 我們要轉回 RGB\n",
    "        # zero-mean\n",
    "        # pre-trained model 使用 ImageNet 做訓練\n",
    "        # ImageNet 的所有影像 RGB 平均值 [123.68, 116.78, 103.94]\n",
    "        #img = img.astype('float32') - np.array([123.68, 116.78, 103.94])\n",
    "        img = img.astype('float32')\n",
    "        x.append(img)\n",
    "        nn=np.zeros(15,dtype=float)\n",
    "        nn[i]=1\n",
    "        y.append(nn)\n",
    "xx=np.array(x)\n",
    "yy=np.array(y)\n",
    "\n",
    "xx = preprocess_input(xx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3823, 299, 299, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3823, 15)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set data dimension\n",
      "(3058, 299, 299, 3)\n",
      "(3058, 15)\n",
      "-----------\n",
      "training set: 3058\n",
      "validation set: 765\n"
     ]
    }
   ],
   "source": [
    "#----------------------------資料training set, testing set 分割---------------------------------------\n",
    "\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(xx, \n",
    "                                                      yy, \n",
    "                                                      test_size = 1.0 - train_ratio,\n",
    "                                                      stratify = y,\n",
    "                                                      random_state = r_state)\n",
    "#------------------------------------檢查資料---------------------------------------------------------\n",
    "print(\"training set data dimension\")\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(\"-----------\")\n",
    "print(\"training set: %i\" % len(x_train))\n",
    "print(\"validation set: %i\" % len(x_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_valid = x_valid.astype('float32')\n",
    "\n",
    "\n",
    "# subtract mean and normalize\n",
    "mean_image = np.mean(x_train, axis=0)\n",
    "x_train -= mean_image\n",
    "x_valid -= mean_image\n",
    "x_train /= 255.\n",
    "x_valid /= 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.01), cooldown=0, patience=5, min_lr=0.5e-6)\n",
    "early_stopper = EarlyStopping(min_delta=0.01, patience=10)\n",
    "mcp_save = ModelCheckpoint('best.hdf5', save_best_only=True, monitor='val_loss', mode='min')\n",
    "csv_logger = CSVLogger('resnet18.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks=[lr_reducer, early_stopper, csv_logger,mcp_save]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=True,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        shear_range = 0.1,\n",
    "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "# datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.densenet import DenseNet201\n",
    "model = DenseNet201(weights = \"imagenet\", include_top=False, input_shape = (sz, sz, channel))\n",
    "\n",
    "# Freeze the layers which you don't want to train. Here I am freezing the first 5 layers.\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "#Adding custom Layers \n",
    "x = model.output\n",
    "x = Flatten()(x)\n",
    "#x = GlobalAveragePooling2D(data_format= \"channels_last\")(x)\n",
    "x = Dense(1024, activation=\"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(15, activation=\"softmax\")(x)\n",
    "\n",
    "# creating the final model \n",
    "model_final = Model(input = model.input, output = predictions)\n",
    "\n",
    "# compile the model \n",
    "model_final.compile(loss = \"categorical_crossentropy\", optimizer=optimizers.Adam(lr=lr), metrics=[\"accuracy\"])\n",
    "\n",
    "#model_final.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      " 51/101 [==============>...............] - ETA: 22s - loss: 1.5910 - acc: 0.7039"
     ]
    }
   ],
   "source": [
    "history = model_final.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                                    steps_per_epoch=x_train.shape[0] / batch_size,\n",
    "                                    validation_data=(x_valid, y_valid),  \n",
    "                                    epochs=epochs, \n",
    "                                    callbacks=[lr_reducer, early_stopper, csv_logger,mcp_save])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdata=pd.read_csv(data_src+'submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "testdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdataindexlist=testdata.id.as_matrix().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_t=[]\n",
    "for f in testdataindexlist:\n",
    "    img=cv2.imread(data_src+'test/'+f+'.jpg')\n",
    "    img=cv2.resize(img,(sz,sz))\n",
    "    img=cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = img[:,:,::-1] # cv2 預設讀進來是 BGR, 我們要轉回 RGB\n",
    "    #img = img.astype('float32') - np.array([123.68, 116.78, 103.94])\n",
    "    img = img.astype('float32')\n",
    "    x_t.append(img)\n",
    "\n",
    "        \n",
    "x_test=np.array(x_t)\n",
    "x_test = preprocess_input(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%script false\n",
    "model_final.load_weights(filepath = 'best.hdf5')\n",
    "\n",
    "score = model_final.evaluate(x_train, y_train, verbose=2)\n",
    "print(\"Best model\")\n",
    "print('\\t-CV loss:', score[0])\n",
    "print('\\t-CV accuracy:', score[1])\n",
    "\n",
    "pt = model_final.predict(x_train)\n",
    "mse = (np.mean((pt-y_train)**2))\n",
    "print('\\t-CV MSE: ', mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts = model_final.predict(x_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "codeMap = {}\n",
    "maxPossible = np.argmax(predicts,axis=1)\n",
    "for i in range(0, 1500):\n",
    "    filename = testdata.id[i]\n",
    "    code = maxPossible[i]\n",
    "    codeMap[code] = code\n",
    "#     print(i)\n",
    "    result.append([filename,code])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer=pd.DataFrame(result,columns=['id','class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer.to_csv('xception-submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
